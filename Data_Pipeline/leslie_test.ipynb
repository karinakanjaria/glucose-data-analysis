{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "552f4c96-fdeb-44d3-be7c-b6d0a79dbdfa",
   "metadata": {},
   "source": [
    "### Start/loading in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c81bc504-d2bf-4214-8fe1-a50b71fd359f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, TimestampType, StringType, IntegerType, FloatType, DateType\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType, date_trunc, col\n",
    "import pyspark.pandas as ps\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7dd8034d-0af5-47b2-bd2d-e6b7bed4b552",
   "metadata": {
    "tags": []
   },
   "source": [
    "sys.path.append('../../glucose-data-analysis')\n",
    "from Data_Schema.schema import Pandas_UDF_Data_Schema\n",
    "pandas_udf_data_schema=Pandas_UDF_Data_Schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6359523a-589a-4d2f-b4cb-d8f6931c1570",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/10 08:15:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setAll([\\\n",
    "    ('spark.app.name', 'ReduceData')])\n",
    "spark = SparkSession.builder.config(conf=conf)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7283e8fe-e48b-4fc3-b232-3c0a9acdc202",
   "metadata": {},
   "source": [
    "### Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd35ee3-ccb6-4f89-b27c-cd291d122a24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glucose_data_schema=StructType([StructField('NumId', IntegerType(), True),\n",
    "                                        StructField('PatientId', StringType(), True),\n",
    "                                        StructField('Value', FloatType(), True),\n",
    "                                        StructField('GlucoseDisplayTime', TimestampType(), True),\n",
    "                                        StructField('GlucoseDisplayTimeRaw', StringType(), True),\n",
    "                                        StructField('GlucoseDisplayDate', DateType(), True)])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7cf296d9-be78-49ec-8c03-bd520c1bf1d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "from imputation_pipeline import Date_And_Value_Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31782ac6-b045-493f-bc62-7824367347ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.191951513290405\n"
     ]
    }
   ],
   "source": [
    "\"\"\"replicate step1: read in the data\"\"\"\n",
    "startTime = time.time()\n",
    "data_location = \"/cephfs/train_test_val/train_set\"\n",
    "allPaths = [str(x) for x in list(pathlib.Path(data_location).glob('*.parquet')) if 'part-00' in str(x)][0]\n",
    "\n",
    "pyspark_glucose_data = spark.read \\\n",
    "                       .schema(glucose_data_schema) \\\n",
    "                       .format('parquet') \\\n",
    "                       .load(allPaths)\n",
    "pyspark_glucose_data = pyspark_glucose_data.withColumn(\"GlucoseDisplayTime\",\n",
    "                                                       date_trunc(\"minute\",\n",
    "                                                       col(\"GlucoseDisplayTime\")))\n",
    "\n",
    "'''drop duplicate datetimes for each patient'''\n",
    "window = Window.partitionBy('GlucoseDisplayTime','PatientId').orderBy('tiebreak')\n",
    "df = (df\n",
    " .withColumn('tiebreak', monotonically_increasing_id())\n",
    " .withColumn('rank', rank().over(window))\n",
    " .filter(col('rank') == 1).drop('rank','tiebreak')\n",
    ")\n",
    "\n",
    "pyspark_glucose_data=pyspark_glucose_data.orderBy(\"PatientId\",\n",
    "                                                  \"GlucoseDisplayTime\",\n",
    "                                                  ascending=True)\n",
    "\n",
    "print(time.time()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aec275c6-40d2-4e91-a9e6-e0e8ef4b203e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/glucose-data-analysis/glucose_venv/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:248: FutureWarning: Passing unit-less datetime64 dtype to .astype is deprecated and will raise in a future version. Pass 'datetime64[ns]' instead\n",
      "  series = series.astype(t, copy=False)\n"
     ]
    }
   ],
   "source": [
    "test_df = pyspark_glucose_data.toPandas()\n",
    "test_df = test_df.drop(columns=['PatientId','GlucoseDisplayTimeRaw','GlucoseDisplayDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f97f60b-68fa-4e77-879d-8ef0e7da4cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150016 entries, 0 to 58814\n",
      "Data columns (total 4 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   NumId               150016 non-null  int64         \n",
      " 1   Value               58815 non-null   float32       \n",
      " 2   GlucoseDisplayTime  150016 non-null  datetime64[ns]\n",
      " 3   TimeLag             150016 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float32(1), int64(1)\n",
      "memory usage: 5.2 MB\n",
      "None \n",
      "\n",
      "27\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 149989 entries, 1 to 58814\n",
      "Data columns (total 3 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   NumId               149989 non-null  int64         \n",
      " 1   Value               58788 non-null   float32       \n",
      " 2   GlucoseDisplayTime  149989 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float32(1), int64(1)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "min_max = test_df.groupby('NumId')\\\n",
    "            .agg({'GlucoseDisplayTime' : ['min', 'max']})\n",
    "\n",
    "merge_df = pd.DataFrame(columns=['GlucoseDisplayTime', 'NumId'])\n",
    "for idx, row in min_max.iterrows():\n",
    "    # print(test_df[test_df['NumId'] == idx].info(),\"\\n\")\n",
    "    #grab all potential dates in range\n",
    "\n",
    "    date_df = pd.DataFrame(pd.date_range(row[0], row[1], freq='5min'), columns=['GlucoseDisplayTime'])                              \n",
    "    date_df['NumId'] = idx\n",
    "\n",
    "    # merge dates with big pypsark df\n",
    "    merged = test_df[test_df['NumId'] == idx]\\\n",
    "            .merge(date_df, how='outer', on=['GlucoseDisplayTime', 'NumId'])\\\n",
    "            .sort_values(by=['GlucoseDisplayTime', 'Value'], na_position='last')\n",
    "\n",
    "    merged['TimeLag'] = np.concatenate((merged['GlucoseDisplayTime'].iloc[0],\\\n",
    "                                        np.array(merged['GlucoseDisplayTime'].iloc[:-1].values)), axis=None)\\\n",
    "                        .astype('datetime64[ns]')\n",
    "    print(merged.info(),\"\\n\")\n",
    "\n",
    "    merged['Diff'] = (merged['TimeLag'] - merged['GlucoseDisplayTime']).dt.seconds\n",
    "\n",
    "    len_merged = len(merged)\n",
    "\n",
    "    # get all index of rows with diff less than 5 mins, add 1 to remove next row, \n",
    "    # dont include last row to delete\n",
    "    indexes_to_remove = [x for x in merged[merged['Diff'] < 300].index + 1 if x < len_merged]\n",
    "\n",
    "    if len(indexes_to_remove) > 0:\n",
    "        merged = merged.drop(indexes_to_remove)\n",
    "\n",
    "    merged = merged.drop(columns=['TimeLag','Diff'])\n",
    "\n",
    "    # its ready freddy for some interpoletty\n",
    "    merge_df = pd.concat([merge_df,merged])\n",
    "\n",
    "    break\n",
    "    \n",
    "# merge_df\n",
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54b835d1-5974-4e14-be87-4b353d59c1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumId</th>\n",
       "      <th>Value</th>\n",
       "      <th>GlucoseDisplayTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2022-02-01 00:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2022-02-01 00:11:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46156</th>\n",
       "      <td>149</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2022-11-17 04:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46157</th>\n",
       "      <td>149</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2022-11-17 04:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46165</th>\n",
       "      <td>149</td>\n",
       "      <td>215.0</td>\n",
       "      <td>2022-11-17 05:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46166</th>\n",
       "      <td>149</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2022-11-17 05:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46169</th>\n",
       "      <td>149</td>\n",
       "      <td>212.0</td>\n",
       "      <td>2022-11-17 05:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46170</th>\n",
       "      <td>149</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2022-11-17 05:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46177</th>\n",
       "      <td>149</td>\n",
       "      <td>178.0</td>\n",
       "      <td>2022-11-17 06:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46178</th>\n",
       "      <td>149</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2022-11-17 06:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46178</th>\n",
       "      <td>149</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2022-11-17 06:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46179</th>\n",
       "      <td>149</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2022-11-17 06:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46189</th>\n",
       "      <td>149</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2022-11-17 07:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46190</th>\n",
       "      <td>149</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2022-11-17 07:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46191</th>\n",
       "      <td>149</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2022-11-17 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46192</th>\n",
       "      <td>149</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2022-11-17 08:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46193</th>\n",
       "      <td>149</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2022-11-17 08:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46194</th>\n",
       "      <td>149</td>\n",
       "      <td>143.0</td>\n",
       "      <td>2022-11-17 08:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46196</th>\n",
       "      <td>149</td>\n",
       "      <td>156.0</td>\n",
       "      <td>2022-11-17 08:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46197</th>\n",
       "      <td>149</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2022-11-17 08:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46197</th>\n",
       "      <td>149</td>\n",
       "      <td>160.0</td>\n",
       "      <td>2022-11-17 08:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46198</th>\n",
       "      <td>149</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2022-11-17 08:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46200</th>\n",
       "      <td>149</td>\n",
       "      <td>151.0</td>\n",
       "      <td>2022-11-17 08:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46201</th>\n",
       "      <td>149</td>\n",
       "      <td>141.0</td>\n",
       "      <td>2022-11-17 08:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46205</th>\n",
       "      <td>149</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2022-11-17 08:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46206</th>\n",
       "      <td>149</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2022-11-17 08:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46206</th>\n",
       "      <td>149</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2022-11-17 08:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46207</th>\n",
       "      <td>149</td>\n",
       "      <td>136.0</td>\n",
       "      <td>2022-11-17 08:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46211</th>\n",
       "      <td>149</td>\n",
       "      <td>185.0</td>\n",
       "      <td>2022-11-17 09:12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46212</th>\n",
       "      <td>149</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2022-11-17 09:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46212</th>\n",
       "      <td>149</td>\n",
       "      <td>182.0</td>\n",
       "      <td>2022-11-17 09:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46213</th>\n",
       "      <td>149</td>\n",
       "      <td>137.0</td>\n",
       "      <td>2022-11-17 09:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46218</th>\n",
       "      <td>149</td>\n",
       "      <td>180.0</td>\n",
       "      <td>2022-11-17 09:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46219</th>\n",
       "      <td>149</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2022-11-17 09:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46221</th>\n",
       "      <td>149</td>\n",
       "      <td>174.0</td>\n",
       "      <td>2022-11-17 09:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46222</th>\n",
       "      <td>149</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2022-11-17 10:02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46228</th>\n",
       "      <td>149</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2022-11-17 10:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46229</th>\n",
       "      <td>149</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2022-11-17 10:47:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46230</th>\n",
       "      <td>149</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2022-11-17 10:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46231</th>\n",
       "      <td>149</td>\n",
       "      <td>139.0</td>\n",
       "      <td>2022-11-17 10:52:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46234</th>\n",
       "      <td>149</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2022-11-17 11:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46235</th>\n",
       "      <td>149</td>\n",
       "      <td>138.0</td>\n",
       "      <td>2022-11-17 11:07:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46237</th>\n",
       "      <td>149</td>\n",
       "      <td>158.0</td>\n",
       "      <td>2022-11-17 11:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46238</th>\n",
       "      <td>149</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2022-11-17 11:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46239</th>\n",
       "      <td>149</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2022-11-17 11:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46240</th>\n",
       "      <td>149</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2022-11-17 11:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46242</th>\n",
       "      <td>149</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2022-11-17 11:27:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46243</th>\n",
       "      <td>149</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2022-11-17 11:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46244</th>\n",
       "      <td>149</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2022-11-17 11:37:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46245</th>\n",
       "      <td>149</td>\n",
       "      <td>129.0</td>\n",
       "      <td>2022-11-17 11:42:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46252</th>\n",
       "      <td>149</td>\n",
       "      <td>147.0</td>\n",
       "      <td>2022-11-17 12:17:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46253</th>\n",
       "      <td>149</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2022-11-17 12:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46254</th>\n",
       "      <td>149</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2022-11-17 12:22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46255</th>\n",
       "      <td>149</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2022-11-17 12:37:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NumId  Value  GlucoseDisplayTime\n",
       "0        149  112.0 2022-02-01 00:06:00\n",
       "1        149  110.0 2022-02-01 00:11:00\n",
       "46156    149  143.0 2022-11-17 04:42:00\n",
       "46157    149  112.0 2022-11-17 04:42:00\n",
       "46165    149  215.0 2022-11-17 05:27:00\n",
       "46166    149  150.0 2022-11-17 05:27:00\n",
       "46169    149  212.0 2022-11-17 05:42:00\n",
       "46170    149  149.0 2022-11-17 05:42:00\n",
       "46177    149  178.0 2022-11-17 06:42:00\n",
       "46178    149  180.0 2022-11-17 06:47:00\n",
       "46178    149  180.0 2022-11-17 06:47:00\n",
       "46179    149  143.0 2022-11-17 06:47:00\n",
       "46189    149  147.0 2022-11-17 07:47:00\n",
       "46190    149  143.0 2022-11-17 07:57:00\n",
       "46191    149  143.0 2022-11-17 08:02:00\n",
       "46192    149  136.0 2022-11-17 08:02:00\n",
       "46193    149  147.0 2022-11-17 08:07:00\n",
       "46194    149  143.0 2022-11-17 08:07:00\n",
       "46196    149  156.0 2022-11-17 08:12:00\n",
       "46197    149  160.0 2022-11-17 08:17:00\n",
       "46197    149  160.0 2022-11-17 08:17:00\n",
       "46198    149  141.0 2022-11-17 08:17:00\n",
       "46200    149  151.0 2022-11-17 08:27:00\n",
       "46201    149  141.0 2022-11-17 08:27:00\n",
       "46205    149  147.0 2022-11-17 08:42:00\n",
       "46206    149  167.0 2022-11-17 08:52:00\n",
       "46206    149  167.0 2022-11-17 08:52:00\n",
       "46207    149  136.0 2022-11-17 08:52:00\n",
       "46211    149  185.0 2022-11-17 09:12:00\n",
       "46212    149  182.0 2022-11-17 09:17:00\n",
       "46212    149  182.0 2022-11-17 09:17:00\n",
       "46213    149  137.0 2022-11-17 09:17:00\n",
       "46218    149  180.0 2022-11-17 09:47:00\n",
       "46219    149  142.0 2022-11-17 09:47:00\n",
       "46221    149  174.0 2022-11-17 09:57:00\n",
       "46222    149  142.0 2022-11-17 10:02:00\n",
       "46228    149  164.0 2022-11-17 10:42:00\n",
       "46229    149  159.0 2022-11-17 10:47:00\n",
       "46230    149  159.0 2022-11-17 10:52:00\n",
       "46231    149  139.0 2022-11-17 10:52:00\n",
       "46234    149  155.0 2022-11-17 11:07:00\n",
       "46235    149  138.0 2022-11-17 11:07:00\n",
       "46237    149  158.0 2022-11-17 11:17:00\n",
       "46238    149  133.0 2022-11-17 11:17:00\n",
       "46239    149  159.0 2022-11-17 11:22:00\n",
       "46240    149  127.0 2022-11-17 11:22:00\n",
       "46242    149  159.0 2022-11-17 11:27:00\n",
       "46243    149  129.0 2022-11-17 11:37:00\n",
       "46244    149  154.0 2022-11-17 11:37:00\n",
       "46245    149  129.0 2022-11-17 11:42:00\n",
       "46252    149  147.0 2022-11-17 12:17:00\n",
       "46253    149  130.0 2022-11-17 12:22:00\n",
       "46254    149  146.0 2022-11-17 12:22:00\n",
       "46255    149  126.0 2022-11-17 12:37:00"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = [i - 1 for i in indexes_to_remove] + indexes_to_remove\n",
    "temp.sort()\n",
    "merged.loc[temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a5dd700-10a3-4c28-a77f-3e4ed3b26b60",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 46156,\n",
       " 46157,\n",
       " 46165,\n",
       " 46166,\n",
       " 46169,\n",
       " 46170,\n",
       " 46177,\n",
       " 46178,\n",
       " 46178,\n",
       " 46179,\n",
       " 46189,\n",
       " 46190,\n",
       " 46191,\n",
       " 46192,\n",
       " 46193,\n",
       " 46194,\n",
       " 46196,\n",
       " 46197,\n",
       " 46197,\n",
       " 46198,\n",
       " 46200,\n",
       " 46201,\n",
       " 46205,\n",
       " 46206,\n",
       " 46206,\n",
       " 46207,\n",
       " 46211,\n",
       " 46212,\n",
       " 46212,\n",
       " 46213,\n",
       " 46218,\n",
       " 46219,\n",
       " 46221,\n",
       " 46222,\n",
       " 46228,\n",
       " 46229,\n",
       " 46230,\n",
       " 46231,\n",
       " 46234,\n",
       " 46235,\n",
       " 46237,\n",
       " 46238,\n",
       " 46239,\n",
       " 46240,\n",
       " 46242,\n",
       " 46243,\n",
       " 46244,\n",
       " 46245,\n",
       " 46252,\n",
       " 46253,\n",
       " 46254,\n",
       " 46255]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a4c07-25ee-4f48-a972-d2df47bcd1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose-venv",
   "language": "python",
   "name": "glucose-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
