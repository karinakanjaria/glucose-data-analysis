{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f4fcfa-05d1-4a1e-b01f-2fe3deccc6fb",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee9aad-48b9-4fc9-be7e-a00e8017c397",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n"
     ]
    }
   ],
   "source": [
    "# !sudo apt update\n",
    "# !sudo apt install openjdk-17-jre-headless -y\n",
    "import pyspark\n",
    "from pyspark import pandas as ps\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.functions import col, lag, when, isnull\n",
    "from pyspark.sql.types import StructType, StructField, \\\n",
    "StringType, IntegerType, TimestampType, DateType, FloatType\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422056a1-39af-4067-9e7c-9a53ffbb41dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/01 19:20:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setAll([\\\n",
    "            ('spark.master', 'local[*]'),\\\n",
    "            ('spark.app.name', 'Glucose_Analysis_Spark')])\\\n",
    "            .set('spark.sql.shuffle.partitions', '1500')\n",
    "spark = SparkSession.builder.config(conf=conf)\\\n",
    "    .getOrCreate()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894b4b3c-b5e4-4c5d-8bf8-2c2664a3d136",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet('/cephfs/stepped_glucose_data/step0_load_daily/parquet_0/part-00000-1c9c2511-4c2e-40c2-b7d1-7827039567e8-c000.snappy.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d976072a-9b43-4c1b-860a-2848632c0690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PatientId', 'string'),\n",
       " ('Value', 'float'),\n",
       " ('GlucoseDisplayTime', 'timestamp'),\n",
       " ('GlucoseDisplayTimeRaw', 'string'),\n",
       " ('GlucoseDisplayDate', 'date')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "586c5054-6e86-4c01-873e-e26333d36e2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "patientIds = df.select('PatientId').distinct().select(col('PatientId')).collect()\n",
    "print(len(patientIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c71468db-9f57-490e-a4c2-f825ec9aa398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 79:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+---------------------+------------------+---------+-------+\n",
      "|           PatientId|Value| GlucoseDisplayTime|GlucoseDisplayTimeRaw|GlucoseDisplayDate|FirstDiff|SecDiff|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+---------+-------+\n",
      "|++KoJktK3094kd1l4...|144.0|2022-01-31 17:44:40| 2022-01-31T17:44:...|        2022-01-31|      0.0|    0.0|\n",
      "|++KoJktK3094kd1l4...|150.0|2022-01-31 17:49:39| 2022-01-31T17:49:...|        2022-01-31|      6.0|    6.0|\n",
      "|++KoJktK3094kd1l4...|151.0|2022-01-31 17:54:40| 2022-01-31T17:54:...|        2022-01-31|      1.0|   -5.0|\n",
      "|++KoJktK3094kd1l4...|152.0|2022-01-31 17:59:40| 2022-01-31T17:59:...|        2022-01-31|      1.0|    0.0|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+---------+-------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "my_window = Window.partitionBy('PatientId').orderBy(\"GlucoseDisplayTime\")\n",
    "df = df.withColumn(\"prev_value\", lag(df.Value).over(my_window))\n",
    "df = df.withColumn(\"FirstDiff\", when(isnull(df.Value - df.prev_value), 0)\n",
    "                          .otherwise(df.Value - df.prev_value))\n",
    "\n",
    "df = df.withColumn(\"prev_val_sec\", lag(df.FirstDiff).over(my_window))\n",
    "df = df.withColumn(\"SecDiff\", when(isnull(df.first_diff - df.prev_val_sec), 0)\n",
    "                          .otherwise(df.first_diff - df.prev_val_sec))\n",
    "\n",
    "df = df.drop('prev_value', 'prev_val_sec')\n",
    "\n",
    "df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose-venv",
   "language": "python",
   "name": "glucose-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
