{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a1ff94-8b89-410f-b778-d83999af578d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install xgboost\n",
    "! pip install pandas\n",
    "! pip install scikit-learn\n",
    "! pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f1ce7-f956-4b4f-b62f-d01f8591df08",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################ Libraries ################################\n",
    "from Input_Variables.read_vars import xgboost_regression_model_storage_location, \\\n",
    "                                      linear_regression_model_storage_location, \\\n",
    "                                      random_forest_regression_model_storage_location, \\\n",
    "                                      factorization_machines_regression_model_storage, \\\n",
    "                                      xgboost_classification_model_storage_location, \\\n",
    "                                      logistic_regression_classification_model_storage_location, \\\n",
    "                                      random_forest_classification_model_storage_location, \\\n",
    "                                      multilayer_perceptron_classification_model_storage_location, \\\n",
    "                                      naive_bayes_classification_model_storage_location, \\\n",
    "                                      factorization_machine_classification_model_storage_location, \\\n",
    "                                      random_seed\n",
    "from Read_In_Data.read_data import Reading_Data\n",
    "from Data_Pipeline.scaling_pipeline import Feature_Transformations\n",
    "from Model_Creation.regression_models import Create_Regression_Models\n",
    "from Model_Creation.classification_models import Create_Classification_Models\n",
    "import os\n",
    "\n",
    "\n",
    "################################ Read In Modules ################################\n",
    "reading_data=Reading_Data()\n",
    "feature_transformations=Feature_Transformations()\n",
    "create_regression_models=Create_Regression_Models()\n",
    "create_classification_models=Create_Classification_Models()\n",
    "\n",
    "\n",
    "################################ Regression, Classification, Or Both ################################\n",
    "train_regression=False\n",
    "train_classification=True\n",
    "\n",
    "\n",
    "################################ Read In Data ################################\n",
    "# Training Summary Stats Data\n",
    "training_files=list(map(lambda x: os.path.join(os.path.abspath('/cephfs/summary_stats/all_train_bool_updated'),x),\n",
    "                                               os.listdir('/cephfs/summary_stats/all_train_bool_updated')))\n",
    "training_files=[i for i in training_files if not ('.crc' in i or 'SUCCESS' in i)]\n",
    "\n",
    "\n",
    "# Cross Validation Summary Stats Data\n",
    "val_files=list(map(lambda x: os.path.join(os.path.abspath('/cephfs/summary_stats/all_val_bool_updated'), x),\n",
    "                                          os.listdir('/cephfs/summary_stats/all_val_bool_updated')))\n",
    "val_files=[i for i in val_files if not ('.crc' in i or 'SUCCESS' in i)]\n",
    "\n",
    "\n",
    "# Calling DataFrames\n",
    "summary_stats_train=reading_data.read_in_all_summary_stats(file_list=training_files)\n",
    "summary_stats_val=reading_data.read_in_all_summary_stats(file_list=val_files)\n",
    "\n",
    "\n",
    "################################ Combine Train and Cross Validation ################################\n",
    "df_train_val_combined=summary_stats_train.union(summary_stats_val)\n",
    "df_train_val_combined.show(2)\n",
    "print((df_train_val_combined.count(), len(df_train_val_combined.columns)))\n",
    "\n",
    "\n",
    "################################ Stages: Scaling Using Custom Transformer ################################\n",
    "pipeline_transformation_stages=feature_transformations.numerical_scaling(df=df_train_val_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780fe2c-3237-4e8e-ac07-f3f172c2586c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from xgboost.spark import SparkXGBClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64fb77-2b5c-47fb-898b-6bca2741b582",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_col=\"features\"\n",
    "label_name=\"target\"\n",
    "prediction_column_name=\"prediction\"\n",
    "num_folds=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e060354f-da20-4dcb-af9f-f1be9882230c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mapping= {0: 0, 1: 1, -1: 2}\n",
    "df_train_val_combined=df_train_val_combined.replace(to_replace=mapping, subset=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5611cf5-90b0-441b-a857-3c555367eb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layers = [4, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71313938-f286-4508-8344-bc23e76db359",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp=FMClassifier(featuresCol=features_col, \n",
    "               labelCol=label_name,\n",
    "                seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3171591-a146-4c96-b820-c262a438f26b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_transformation_stages.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c8db2-3c1a-40b6-bce7-0b48fd3d288d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_transformation_stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a61984-3756-4dd1-a9de-0c454cfde986",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_transformation_stages.append(mlp)\n",
    "pipeline=Pipeline(stages=pipeline_transformation_stages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a668f7d8-5d44-42a2-b111-610ed0a65386",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=pipeline.fit(df_train_val_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338992e-b51b-4b8a-af5f-43c69601c988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1232e-4aff-400d-8d60-0b95d904dc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d2eb1-d073-4c5d-a838-84ffb41a88fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ml_df=df_train_val_combined.withColumn(\"foldCol\", df_train_val_combined.NumId % num_folds)\n",
    "\n",
    "evaluator_logloss=MulticlassClassificationEvaluator(metricName='logLoss',\n",
    "                                                    labelCol=label_name,\n",
    "                                                    predictionCol=prediction_column_name)\n",
    "paramGrid=ParamGridBuilder().build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c43aba-dedd-48a4-ac8e-23bf4c44e0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crossval=CrossValidator(estimator=xgb,\n",
    "                        evaluator=evaluator_logloss,\n",
    "                        estimatorParamMaps=paramGrid,\n",
    "                        foldCol='foldCol',\n",
    "                        collectSubModels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4518b1fb-4cdf-4a1b-9697-ceedcd285edb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_transformation_stages.append(crossval)\n",
    "pipeline=Pipeline(stages=pipeline_transformation_stages)\n",
    "\n",
    "model=pipeline.fit(ml_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea67e8a7-2fcd-4601-be2e-9c50311e7ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b49d4a4-62d7-4fb9-b931-2c11a46b3522",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a77826-780d-4dfb-9c21-ad16a30be82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "        location_counter=0\n",
    "        model_types=['XGBoost', 'Logistic_Regression', 'Random_Forest', 'Multilayer_Perceptron', 'Naive_Bayes', 'Factorization_Machine']\n",
    "        model_mapping={'XGBoost': SparkXGBClassifier(features_col=self.features_col, \n",
    "                                                     label_col=self.label_name,\n",
    "                                                     random_state=random_seed,\n",
    "                                                     use_gpu=True),\n",
    "                       \n",
    "                       'Logistic_Regression': LogisticRegression(featuresCol=self.features_col, \n",
    "                                                                 labelCol=self.label_name,\n",
    "                                                                 standardization=False),\n",
    "                       \n",
    "                       'Random_Forest': RandomForestClassifier(featuresCol=self.features_col, \n",
    "                                                               labelCol=self.label_name,\n",
    "                                                               seed=random_seed),\n",
    "                       \n",
    "                       'Multilayer_Perceptron': MultilayerPerceptronClassifier(featuresCol=self.features_col, \n",
    "                                                                               labelCol=self.label_name,\n",
    "                                                                               seed=random_seed),\n",
    "                       \n",
    "                       'Naive_Bayes': NaiveBayes(featuresCol=self.features_col, \n",
    "                                                 labelCol=self.label_name),\n",
    "                       \n",
    "                       'Factorization_Machine': FMClassifier(featuresCol=self.features_col, \n",
    "                                                             labelCol=self.label_name,\n",
    "                                                             seed=random_seed)\n",
    "                      }\n",
    "        \n",
    "        ml_df=ml_df.withColumn(\"foldCol\", ml_df.NumId % num_folds)\n",
    "        \n",
    "        evaluator_logloss=MulticlassClassificationEvaluator(metricName='logLoss',\n",
    "                                                            labelCol=self.label_name,\n",
    "                                                            predictionCol=self.prediction_column_name)\n",
    "        paramGrid=ParamGridBuilder().build()\n",
    "        \n",
    "        for model_type in model_types:\n",
    "            if location_counter > 0:\n",
    "                stages.pop()\n",
    "                print(f'Currently on {model_type} Model')\n",
    "            else:\n",
    "                print(f'Currently on {model_type} Model')\n",
    "            crossval=CrossValidator(estimator=model_mapping[model_type],\n",
    "                                    evaluator=evaluator_logloss,\n",
    "                                    estimatorParamMaps=paramGrid,\n",
    "                                    foldCol='foldCol',\n",
    "                                    collectSubModels=False)\n",
    "\n",
    "            print('Cross Validation Occuring')\n",
    "            stages.append(crossval)\n",
    "            pipeline=Pipeline(stages=stages)\n",
    "\n",
    "            model=pipeline.fit(ml_df)\n",
    "\n",
    "            model.write().overwrite().save(classification_models_storage_locations[location_counter])\n",
    "            print(f'Model Saved to {classification_models_storage_locations[location_counter]}')\n",
    "            location_counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adcf262-568e-4c88-a5f3-d2787b48dad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8ea15fe-f0fe-4e6f-959a-9a2f0ff2a2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline, PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab497fc0-ccff-41da-aa7d-9e127113295c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 20:58:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/31 20:58:33 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+-----+-----+--------------------+--------------------+-----------------+------------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|NumId|Chunk|ShortTermVariance|LongTermVariance|VarianceRatio|SampleEntropy|PermutationEntropy|              Mean|            StdDev|Median|  Min|  Max|        AvgFirstDiff|          AvgSecDiff|     StdFirstDiff|        StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|DiffPrevious|target|Sex_Female|Sex_Male|Treatment_yes_both|Treatment_yes_long_acting|Treatment_no|Treatment_yes_fast_acting|AgeGroup_50|AgeGroup_60|AgeGroup_70|AgeGroup_40|AgeGroup_30|AgeGroup_80|AgeGroup_90|AgeGroup_10|\n",
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+-----+-----+--------------------+--------------------+-----------------+------------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "|  283|    5|          8.38934|       10.179978|     0.824102|    0.0080617|         0.2331243|151.92013888888889|22.006426302035383| 149.0|112.0|301.0|-0.10416666666666667|-0.01388888888888...|9.327729257490555|11.843630500404851|        13|         0|             13|         -13|    -1|         1|       0|                 0|                        0|           1|                        0|          0|          1|          0|          0|          0|          0|          0|          0|\n",
      "|  283|   13|         9.193268|       14.749492|   0.62329394|  0.019841177|         0.6159319|141.42708333333334| 46.47956610523607| 149.0| 39.0|362.0| -0.3020833333333333|-0.05555555555555555|12.46552301098042|13.063648944000844|        21|         8|             29|          10|     1|         1|       0|                 0|                        0|           1|                        0|          0|          1|          0|          0|          0|          0|          0|          0|\n",
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+-----+-----+--------------------+--------------------+-----------------+------------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "(881104, 35)\n"
     ]
    }
   ],
   "source": [
    "################################ Libraries ################################\n",
    "# from Input_Variables.read_vars import xgb_reg_model_storage_location, xgb_class_model_storage_location, random_seed, \\\n",
    "#                                       evaluation_metrics_output_storage, \\\n",
    "#                                       feature_importance_storage_location, \\\n",
    "#                                       overall_feature_importance_plot_location\n",
    "from Read_In_Data.read_data import Reading_Data\n",
    "\n",
    "from Model_Predictions.pyspark_model_preds import Model_Predictions\n",
    "from Model_Evaluation.pyspark_model_eval import Evaluate_Model\n",
    "from Feature_Importance.model_feature_importance import Feature_Importance\n",
    "from Model_Plots.xgboost_classification_plots import XGBoost_Classification_Plot\n",
    "import os\n",
    "\n",
    "\n",
    "################################ Read In Modules ################################\n",
    "reading_data=Reading_Data()\n",
    "\n",
    "# model_predictions=Model_Predictions()\n",
    "# evaluate_model=Evaluate_Model()\n",
    "# feature_importance=Feature_Importance()\n",
    "# xgboost_classification_plot=XGBoost_Classification_Plot()\n",
    "\n",
    "\n",
    "################################ Read In Data ################################\n",
    "# Testing Summary Stats Data\n",
    "test_files=list(map(lambda x: os.path.join(os.path.abspath('/cephfs/summary_stats/all_test_bool_updated'), x),\n",
    "                                           os.listdir('/cephfs/summary_stats/all_test_bool_updated')))\n",
    "test_files=[i for i in test_files if not ('.crc' in i or 'SUCCESS' in i)]\n",
    "\n",
    "# Calling DataFrames\n",
    "summary_stats_test=reading_data.read_in_all_summary_stats(file_list=test_files)\n",
    "summary_stats_test.show(2)\n",
    "print((summary_stats_test.count(), len(summary_stats_test.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "308bf76c-f69e-4702-b474-f91a4e5bd44b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineModel=PipelineModel.load(\"/cephfs/Saved_Models/No_Hyperparameter_Tuning/Classification/XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3b101e8b-308e-4085-ac65-a3e7ca896262",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds=pipelineModel.transform(summary_stats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "703c829a-9d4d-4e53-b5f5-f6a4000d5927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:50:29] WARNING: ../src/learner.cc:553:                          (0 + 1) / 1]\n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+--------------------+--------------------+----------+------+\n",
      "|NumId|Chunk|       rawPrediction|         probability|prediction|target|\n",
      "+-----+-----+--------------------+--------------------+----------+------+\n",
      "|   12|    1|[1.14917623996734...|[0.51960194110870...|       0.0|     1|\n",
      "|   12|    2|[1.18391394615173...|[0.51820838451385...|       0.0|     0|\n",
      "|   12|    7|[0.92625272274017...|[0.43397551774978...|       0.0|     0|\n",
      "|   12|   17|[1.78566992282867...|[0.77350419759750...|       0.0|     0|\n",
      "|   12|   19|[1.63358390331268...|[0.78384935855865...|       0.0|     0|\n",
      "|   12|   20|[1.21677529811859...|[0.59110909700393...|       0.0|     0|\n",
      "|   12|   30|[1.44567775726318...|[0.66280370950698...|       0.0|     0|\n",
      "|   12|   33|[0.45569711923599...|[0.35991567373275...|       1.0|     0|\n",
      "|   12|   37|[1.68670558929443...|[0.83340883255004...|       0.0|     1|\n",
      "|   12|   40|[1.02925384044647...|[0.60148757696151...|       0.0|     0|\n",
      "|   12|   45|[1.28640818595886...|[0.61943250894546...|       0.0|     0|\n",
      "|   12|   46|[0.35025840997695...|[0.21209181845188...|       2.0|    -1|\n",
      "|   12|   47|[1.72186040878295...|[0.83508926630020...|       0.0|     1|\n",
      "|   12|   53|[1.37376856803894...|[0.62808394432067...|       0.0|     1|\n",
      "|   12|   57|[-0.4656492173671...|[0.06701904535293...|       2.0|    -1|\n",
      "|   12|   67|[0.58392703533172...|[0.25323879718780...|       2.0|    -1|\n",
      "|   12|   68|[1.28359138965606...|[0.60672819614410...|       0.0|     1|\n",
      "|   12|   69|[-0.3078459203243...|[0.07584860920906...|       2.0|    -1|\n",
      "|   12|   76|[1.21958041191101...|[0.59003001451492...|       0.0|     0|\n",
      "|   12|   78|[1.08325338363647...|[0.47491240501403...|       1.0|     1|\n",
      "+-----+-----+--------------------+--------------------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.select('NumId', 'Chunk', 'rawPrediction', 'probability', 'prediction', 'target').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7904f80b-18cc-47b4-9537-16ae0f645228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[22:49:53] WARNING: ../src/learner.cc:553:                          (0 + 1) / 1]\n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+----+-----+--------------------+--------------------+-----------------+-----------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+-----------------------+--------------------+--------------------+-------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+----------------------+--------------------+--------------------+----------+--------------------+\n",
      "|NumId|Chunk|ShortTermVariance|LongTermVariance|VarianceRatio|SampleEntropy|PermutationEntropy|              Mean|            StdDev|Median| Min|  Max|        AvgFirstDiff|          AvgSecDiff|     StdFirstDiff|       StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|DiffPrevious|target|Sex_Female|Sex_Male|Treatment_yes_both|Treatment_yes_long_acting|Treatment_no|Treatment_yes_fast_acting|AgeGroup_50|AgeGroup_60|AgeGroup_70|AgeGroup_40|AgeGroup_30|AgeGroup_80|AgeGroup_90|AgeGroup_10|scaled_ShortTermVariance|scaled_LongTermVariance|scaled_VarianceRatio|scaled_SampleEntropy|scaled_PermutationEntropy|        scaled_Mean|      scaled_StdDev|      scaled_Median|         scaled_Min|          scaled_Max| scaled_AvgFirstDiff|   scaled_AvgSecDiff|scaled_StdFirstDiff|  scaled_StdSecDiff|  scaled_CountAbove|   scaled_CountBelow|scaled_TotalOutOfRange|            features|       rawPrediction|prediction|         probability|\n",
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+----+-----+--------------------+--------------------+-----------------+-----------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+-----------------------+--------------------+--------------------+-------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+----------------------+--------------------+--------------------+----------+--------------------+\n",
      "|   12|    1|         5.377043|        5.545522|    0.9696188|     0.614895|         1.1562096|127.20833333333333|12.832545189005739| 127.0|85.0|165.0|-0.01041666666666...|0.003472222222222222|5.462245696486059|7.591255864612467|         0|         0|              0|          54|     1|         0|       1|                 0|                        0|           1|                        0|          0|          0|          0|          0|          0|          1|          0|          0|     -1.4182336105890898|     1.7159373544384633| -0.7521059349221095|  2.8504482409699916|       1.9854077675080426|-0.6443055902784609|-0.4848028517690339|-1.4410138169451383|-0.3735187782062986| -0.5700902247690995|-0.09660890712674819|0.014622224535438197|-1.3542538269722117|-1.4220658292020323|-0.6130839025336582|-0.29219155785937007|   -0.6573851949163217|[-1.4182336105890...|[1.14917623996734...|       0.0|[0.51960194110870...|\n",
      "|   12|    2|        3.1210637|       5.5328465|    0.5640973|   0.14391787|         1.0352873|129.82986111111111|18.215384162561648| 132.0|96.0|173.0|            -0.03125|-0.01736111111111...|4.491850440884609| 4.40656510317472|         0|         0|              0|           0|     0|         0|       1|                 0|                        0|           1|                        0|          0|          0|          0|          0|          0|          1|          0|          0|     -1.5475991309562291|     1.7079676592498545| -0.7700609960981156| -1.2214669965727551|       0.9294608332460126|-0.2617451171803963|0.24317798322967246| 0.2946202338288675|0.19107253896696372|-0.31859537121016407| -0.2659806305586557|-0.14471952528427023|-1.4353690242172499|-1.5510903718940257|-0.6130839025336582|-0.29219155785937007|   -0.6573851949163217|[-1.5475991309562...|[1.18391394615173...|       0.0|[0.51820838451385...|\n",
      "+-----+-----+-----------------+----------------+-------------+-------------+------------------+------------------+------------------+------+----+-----+--------------------+--------------------+-----------------+-----------------+----------+----------+---------------+------------+------+----------+--------+------------------+-------------------------+------------+-------------------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------------------+-----------------------+--------------------+--------------------+-------------------------+-------------------+-------------------+-------------------+-------------------+--------------------+--------------------+--------------------+-------------------+-------------------+-------------------+--------------------+----------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c078a8-2a13-4690-a88d-6a01cdedb323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5e1a5-0397-4cca-b886-7ff0d29b1223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fd39fdb-696a-4d41-ba45-2cbdfff5511c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipelineModel=PipelineModel.load(\"/cephfs/Saved_Models/No_Hyperparameter_Tuning/Regression/XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e8bf99a-7d82-43ba-ba78-1aea8407a283",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds=pipelineModel.transform(summary_stats_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0f6dad1-2143-4920-83aa-f5812f2e773d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[21:36:39] WARNING: ../src/learner.cc:553:                          (0 + 1) / 1]\n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|         prediction|DiffPrevious|\n",
      "+-------------------+------------+\n",
      "| 15.160192489624023|          54|\n",
      "| 11.676578521728516|           0|\n",
      "|  5.882169723510742|          -7|\n",
      "| 3.9520092010498047|           0|\n",
      "|  6.482405185699463|           3|\n",
      "| 1.2447888851165771|          -5|\n",
      "| 10.977035522460938|           3|\n",
      "| 12.524152755737305|          -1|\n",
      "|  6.483696937561035|          16|\n",
      "| 3.5730857849121094|          -2|\n",
      "|   7.81408166885376|           0|\n",
      "|-16.302438735961914|         -18|\n",
      "|  5.971994876861572|          18|\n",
      "| 3.9098498821258545|          12|\n",
      "| -34.38546371459961|         -60|\n",
      "|-18.264915466308594|         -16|\n",
      "| 10.801153182983398|          16|\n",
      "| -23.75125503540039|         -35|\n",
      "| 13.340191841125488|           0|\n",
      "| 15.376773834228516|          12|\n",
      "+-------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "preds.select('prediction', 'DiffPrevious').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357fbb7-c8f8-47a3-a620-2a1a949d21a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose-venv",
   "language": "python",
   "name": "glucose-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
