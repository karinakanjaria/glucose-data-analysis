{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47549336-fd80-4096-8632-5720c21074cd",
   "metadata": {},
   "source": [
    "# Save raw data to 60-20-20 split for train-test-validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff0e015a-3772-4b76-9e8c-e040be0d956a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import when, col, to_date, rank, monotonically_increasing_id\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, TimestampType, DateType, FloatType\n",
    "import pathlib\n",
    "\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78913a50-46fb-4a16-9335-ba050c6f7426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/07 10:41:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/05/07 10:41:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = pyspark.SparkConf().setAll([\\\n",
    "    ('spark.app.name', 'ReduceData')])\n",
    "spark = SparkSession.builder.config(conf=conf)\\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaed09d-fa5e-4784-a365-718748523cf9",
   "metadata": {},
   "source": [
    "### Structs we might need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "762323e2-8854-4f02-bf2c-719d6c17c742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "glucose_data_schema=StructType([StructField('PatientId', StringType(), True),\n",
    "                                StructField('GlucoseDisplayTime', TimestampType(), True),\n",
    "                                StructField('GlucoseDisplayTimeRaw', StringType(), True),\n",
    "                                StructField('Value', FloatType(), True)\n",
    "                                ])\n",
    "\n",
    "raw_schema=StructType([StructField('_c0', IntegerType(),True),\n",
    "                                StructField('PostDate', TimestampType(),True),\n",
    "                                StructField('IngestionDate', TimestampType(),True),\n",
    "                                StructField('PostId', StringType(),True),\n",
    "                                StructField('PostTime', TimestampType(), True),\n",
    "                                StructField('PatientId', StringType(), True),\n",
    "                                StructField('Stream', StringType(), True),\n",
    "                                StructField('SequenceNumber', StringType(), True),\n",
    "                                StructField('TransmitterNumber', StringType(), True),\n",
    "                                StructField('ReceiverNumber', StringType(), True),\n",
    "                                StructField('RecordedSystemTime', TimestampType(), True),\n",
    "                                StructField('RecordedDisplayTime', TimestampType(), True),\n",
    "                                StructField('RecordedDisplayTimeRaw', TimestampType(), True),\n",
    "                                StructField('TransmitterId', StringType(), True),\n",
    "                                StructField('TransmitterTime', StringType(), True),\n",
    "                                StructField('GlucoseSystemTime', TimestampType(), True),\n",
    "                                StructField('GlucoseDisplayTime', TimestampType(), True),\n",
    "                                StructField('GlucoseDisplayTimeRaw', StringType(), True),\n",
    "                                StructField('Value', FloatType(), True),\n",
    "                                StructField('Status', StringType(), True),\n",
    "                                StructField('TrendArrow', StringType(), True),\n",
    "                                StructField('TrendRate', FloatType(), True),\n",
    "                                StructField('IsBackFilled', StringType(), True),\n",
    "                                StructField('InternalStatus', StringType(), True),\n",
    "                                StructField('SessionStartTime', StringType(), True)])\n",
    "\n",
    "cohortSchema = StructType([StructField('', IntegerType(), True),\n",
    "                        StructField('UserId', StringType(), True),\n",
    "                        StructField('Gender', StringType(), True),\n",
    "                        StructField('DOB', TimestampType(), True),\n",
    "                        StructField('Age', IntegerType(), True),\n",
    "                        StructField('DiabetesType', StringType(), True),\n",
    "                        StructField('Treatment', StringType(), True)\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e940d3-d3cc-4fe7-b7bc-b794b8090882",
   "metadata": {},
   "source": [
    "### Get all paths in to read from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4449441-67a3-44c2-a7a4-316ae54aade4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''all CSVs of the raw data'''\n",
    "allPaths = [str(x) for x in list(pathlib.Path('/cephfs/data').glob('*.csv')) if 'glucose_records' in str(x)]\n",
    "allPaths.sort()\n",
    "# trainPaths = allPaths[:219]\n",
    "# valPaths = allPaths[219:292]\n",
    "# testPaths = allPaths[292:]\n",
    "# print(\"train length:\", len(trainPaths), \"\\nvalidation length:\", len(valPaths),\"\\ntest length:\", len(testPaths))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f715afa5-65cf-4af6-b591-ecb88b63733b",
   "metadata": {},
   "source": [
    "### Read in the Cohort dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07c0e057-fdfc-4998-b8e8-521f982e7457",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NumId', 'int'), ('UserId', 'string'), ('Gender', 'string'), ('DOB', 'timestamp'), ('Age', 'int'), ('DiabetesType', 'string'), ('Treatment', 'string')]\n",
      "+-----+--------------------+------+-------------------+---+------------+---------+\n",
      "|NumId|              UserId|Gender|                DOB|Age|DiabetesType|Treatment|\n",
      "+-----+--------------------+------+-------------------+---+------------+---------+\n",
      "|    0|5lZPrCk6qk8L6Jw+S...|Female|1931-01-01 00:00:00| 92|    type-two|       no|\n",
      "|    1|9qY9mZ+GV5Kd/O/NB...|  Male|1937-01-01 00:00:00| 86|    type-two|       no|\n",
      "|    2|uhsyLhr4Zl6NfGbNB...|Female|1938-01-01 00:00:00| 85|    type-two|       no|\n",
      "|    3|9uAVHBOgoCJ9hfcrL...|  Male|1938-01-01 00:00:00| 85|    type-two|       no|\n",
      "|    4|Fyb156jU1edGykL7N...|Female|1939-01-01 00:00:00| 84|    type-two|       no|\n",
      "|    5|86XfZ0fNI0VWOzWrl...|Female|1939-01-01 00:00:00| 84|    type-two|       no|\n",
      "|    6|JfJMH1qCpiYNuPOp/...|Female|1940-01-01 00:00:00| 83|    type-two|       no|\n",
      "|    7|EkW0PD80req7mL/5S...|  Male|1940-01-01 00:00:00| 83|    type-two|       no|\n",
      "|    8|OyqSKorAj1OPZaevj...|Female|1941-01-01 00:00:00| 82|    type-two|       no|\n",
      "|    9|4n03YE5Q5c2Ge1O4+...|Female|1941-01-01 00:00:00| 82|    type-two|       no|\n",
      "+-----+--------------------+------+-------------------+---+------------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      "6.0877954959869385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# read in cohort dataframe, with Number ID properly labeled\n",
    "startTime = time.time()\n",
    "\n",
    "cohortDf = spark.read.options(delimiter=',')\\\n",
    "        .csv('/cephfs/data/cohort.csv', header=True, schema=cohortSchema)\\\n",
    "        .withColumnRenamed('', 'NumId')\n",
    "\n",
    "print(cohortDf.dtypes)\n",
    "cohortDf.show(10)\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd870b0-daaf-4b9f-bbec-be16948f0da3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[UserId: string, NumId: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make mini dataframe of the string IDs and number IDs\n",
    "patientIds = cohortDf.select(col('UserId'), col('NumId')).distinct()\n",
    "patientIds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22241605-090f-4864-a9a5-99a784a051c1",
   "metadata": {},
   "source": [
    "### Load in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fc21e3c-1115-4297-a27b-acaa552709a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:=====================================================> (356 + 2) / 365]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.827446699142456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# aaaaaaaaaaa??\n",
    "startTime = time.time()\n",
    "\n",
    "df = spark.read\\\n",
    "    .format('csv')\\\n",
    "    .option('delimiter', ',')\\\n",
    "    .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "    .option(\"header\", True)\\\n",
    "    .schema(raw_schema)\\\n",
    "    .load(allPaths)\\\n",
    "    .select(col(\"PatientId\"), col(\"Value\"), \\\n",
    "            col(\"GlucoseDisplayTime\"), col(\"GlucoseDisplayTimeRaw\"))\n",
    "\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d5134c-dae7-4aac-8c80-6370c7936583",
   "metadata": {},
   "source": [
    "### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1beb6200-a992-4a21-a382-715491ac3562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04919123649597168\n"
     ]
    }
   ],
   "source": [
    "#add date and sort\n",
    "startTime = time.time()\n",
    "\n",
    "df = df.withColumn('GlucoseDisplayDate',\n",
    "                       to_date(col('GlucoseDisplayTime')))\n",
    "\n",
    "df = df.orderBy(\"PatientId\", \"GlucoseDisplayTime\", ascending=True)\n",
    "\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04f72a60-8a8a-4ac5-92c1-501027484aed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29024362564086914\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"the following cell is leslie's cleanup code, yoinked from fill-missing to read-data to here\"\"\"\n",
    "startTime = time.time()\n",
    "\n",
    "'''get rid of any dates from before the actual start-date of Feb 1, 2022'''\n",
    "df = df.filter(\"GlucoseDisplayDate > date'2022-01-31'\")\n",
    "\n",
    "'''replace 0s with NaN and dropna'''\n",
    "df = df.withColumn(\"Value\", when(col(\"Value\")==\"0\", None) \\\n",
    "                                                       .otherwise(col(\"Value\")))\n",
    "df = df.na.drop(subset=['PatientId','Value','GlucoseDisplayTime'])\n",
    "# df = df.where(df.Value>0)\n",
    "\n",
    "'''drop duplicate datetimes for each patient'''\n",
    "window = Window.partitionBy('GlucoseDisplayTime','PatientId').orderBy('tiebreak')\n",
    "df = (df\n",
    " .withColumn('tiebreak', monotonically_increasing_id())\n",
    " .withColumn('rank', rank().over(window))\n",
    " .filter(col('rank') == 1).drop('rank','tiebreak')\n",
    ")\n",
    "\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528cf3e8-7811-4a30-8f77-42877caf8d1f",
   "metadata": {},
   "source": [
    "### Add in (join) the NumId column"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dd96f52-7db7-40a9-9dd5-3a34db31fa57",
   "metadata": {
    "tags": []
   },
   "source": [
    "#add numId to df\n",
    "startTime = time.time()\n",
    "\n",
    "df = df.join(patientIds, df.PatientId == patientIds.UserId)\\\n",
    "            .select(df.PatientId, df.Value, df.GlucoseDisplayTime, df.GlucoseDisplayTimeRaw, \\\n",
    "                    df.GlucoseDisplayDate, patientIds.NumId)\n",
    "\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5994bb08-2918-4385-93d8-451cacb0ae5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "startTime = time.time()\n",
    "df.show(4)\n",
    "print(time.time() - startTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8c9756-5e17-46c6-98c0-b83ec17c4641",
   "metadata": {},
   "source": [
    "## Split into Train-Test-Val groups of 60-20-20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc68e8b-1aa8-431a-bbf0-95be6209b98c",
   "metadata": {},
   "source": [
    "plan:\n",
    "* get total count of values per patient\n",
    "* make 2 cols:\n",
    "    * int that's the total number of rows that should make up 60% of the patient's data\n",
    "    * int that's the total number of rows that should make up 80% of the patient's data\n",
    "* merge that dataframe back onto the main df dataframe\n",
    "* (is it possible to filter based on another column?)\n",
    "* add ranks based on patient ID\n",
    "* filter once that splits at the 60% mark, asking for 'rank'< or > to the 60% mark\n",
    "    * save the <60% as training\n",
    "* filter the >60% again on the 80% mark\n",
    "    * save the <80% as validation\n",
    "    * save the >80% as test\n",
    "\n",
    "somewhere in there, get rid of patients with less than 80% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc19d043-f14b-41d3-bf63-0a1d2424d159",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84096.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''get total counts of values per patient'''\n",
    "counter = df.groupBy('PatientId').count()\n",
    "# print(\"row count: \", counter.count())\n",
    "\n",
    "'''(?) filter out patients with too little usable data'''\n",
    "minUsable = 0.80 * (60/5 * 24 * 365)\n",
    "counter = counter.filter(col('count') < minUsable)\n",
    "minUsable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ea6d38-e6f1-4235-be30-20c681ae9276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counter = counter.withColumn(\"split60\",(col(\"count\")* 0.6).cast(\"Integer\"))\n",
    "counter = counter.withColumn(\"split80\",(col(\"count\")* 0.8).cast(\"Integer\"))\n",
    "\n",
    "patientIds = patientIds.join(counter, patientIds.UserId == counter.PatientId)\\\n",
    "            .select(patientIds.NumId, patientIds.UserId, counter.split60, counter.split80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0ecdffc-f208-46b5-9701-49356a6b5d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''get everything into order for ranking/sorting by 60%-20%-20%'''\n",
    "joined = df.join(patientIds, df.PatientId == patientIds.UserId)\\\n",
    "            .select(patientIds.NumId, df.PatientId, df.Value, df.GlucoseDisplayTime, \\\n",
    "                    df.GlucoseDisplayTimeRaw, df.GlucoseDisplayDate, \\\n",
    "                    patientIds.split60, patientIds.split80)\n",
    "\n",
    "window = Window.partitionBy('PatientId').orderBy('tiebreak')\n",
    "joined = joined \\\n",
    " .withColumn('tiebreak', monotonically_increasing_id()) \\\n",
    " .withColumn('rank', rank().over(window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eecc0ac4-96b6-47c9-8d2f-1d101e86cf20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''training set'''\n",
    "trainSet = joined.filter(col('rank') <= col('split60')) \\\n",
    "                 .drop('rank','tiebreak','split60','split80')\n",
    "\n",
    "'''validation set'''\n",
    "valSet = joined.filter((col('rank') > col('split60')) & (col('rank') <= col('split80'))) \\\n",
    "               .drop('rank','tiebreak','split60','split80')\n",
    "\n",
    "'''test set'''\n",
    "testSet = joined.filter(col('rank') > col('split80')) \\\n",
    "                .drop('rank','tiebreak','split60','split80')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8274c0-fe09-430b-8ea9-40d037441999",
   "metadata": {},
   "source": [
    "## Save out into parquet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5adc7a54-1ab1-43b1-809f-10d78d6de56b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45887.63158559799\n"
     ]
    }
   ],
   "source": [
    "'''godspeed'''\n",
    "startTime = time.time()\n",
    "\n",
    "# df.repartition('PatientId')\\\n",
    "#     .write.parquet('/cephfs/train_test_val/train/') \n",
    "trainSet.write.parquet('/cephfs/train_test_val/train_set/') \n",
    "valSet.write.parquet('/cephfs/train_test_val/val_set/') \n",
    "testSet.write.parquet('/cephfs/train_test_val/test_set/') \n",
    "\n",
    "print(time.time()-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5abec12d-6820-40a1-9177-98ff0002a933",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.74638888888889"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45887/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54bb3e1-ac41-4309-9eae-ab8c7646281b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose-venv",
   "language": "python",
   "name": "glucose-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
