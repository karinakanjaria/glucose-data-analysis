{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Current Process\n",
    "1. Read in data --> Done\n",
    "\n",
    "2. Custom Imputation --> Done\n",
    "\n",
    "3. Add Binary Class --> Done, Should Add Binary Class Later\n",
    "\n",
    "4. Summary Statistics Features --> Done\n",
    "\n",
    "5. Wrapper Functions --> Done, Need to Test Though\n",
    "\n",
    "6. Sklearn Pipeline Categorical Features --> One Hot Encoding Done\n",
    "\n",
    "7. Sklearn Pipeline Numerical Features --> StandardScaler Done\n",
    "\n",
    "8. Create Lagged Features --> Done\n",
    "\n",
    "9. Modeling --> Currently XgBoost, (Maybe Try: TensorFlow Decision Tree, TensorFlow Probability Model)\n",
    "\n",
    "10. Model Evaluation --> Accuracy, Precision, Recall, F1, Confusion Matrix (Need to add Variable Importance Based on Variance)\n",
    "\n",
    "11. PySpark: XGBoost Classification Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Need to Run These in Notebook Version For Pandas UDF\n",
    "! pip install pyarrow\n",
    "! pip install pandas\n",
    "! pip install scikit-learn\n",
    "! pip install pyspark\n",
    "! pip install xgboost\n",
    "! pip install kaleido\n",
    "! pip install EntropyHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from Input_Variables.read_vars import train_data_storage, validation_data_storage, test_data_storage, \\\n",
    "                                      one_hot_encoding_data, \\\n",
    "                                      analysis_group, \\\n",
    "                                      daily_stats_features_lower, daily_stats_features_upper, \\\n",
    "                                      model_storage_location, random_seed, \\\n",
    "                                      time_series_lag_values_created, \\\n",
    "                                      evaluation_metrics_output_storage, \\\n",
    "                                      feature_importance_storage_location, \\\n",
    "                                      overall_feature_importance_plot_location\n",
    "\n",
    "from Data_Schema.schema import Pandas_UDF_Data_Schema\n",
    "from Read_In_Data.read_data import Reading_Data\n",
    "from Data_Pipeline.imputation_pipeline import Date_And_Value_Imputation\n",
    "\n",
    "\n",
    "from Feature_Generation.create_binary_labels import Create_Binary_Labels\n",
    "from Feature_Generation.summary_stats import Summary_Stats_Features\n",
    "from Feature_Generation.lag_features import Create_Lagged_Features\n",
    "from Feature_Generation.time_series_feature_creation import TS_Features\n",
    "from Feature_Generation.difference_features import Difference_Features\n",
    "\n",
    "from Data_Pipeline.encoding_scaling_pipeline import Feature_Transformations\n",
    "\n",
    "from Model_Creation.pyspark_xgboost import Create_PySpark_XGBoost\n",
    "\n",
    "from Model_Predictions.pyspark_model_preds import Model_Predictions\n",
    "\n",
    "from Model_Evaluation.pyspark_model_eval import Evaluate_Model\n",
    "\n",
    "from Feature_Importance.model_feature_importance import Feature_Importance\n",
    "\n",
    "from Model_Plots.xgboost_classification_plots import XGBoost_Classification_Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 19:41:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# PySpark UDF Schema Activation\n",
    "pandas_udf_data_schema=Pandas_UDF_Data_Schema()\n",
    "\n",
    "# Data Location\n",
    "reading_data=Reading_Data()\n",
    "\n",
    "# Create Binary y Variables\n",
    "create_binary_labels=Create_Binary_Labels()\n",
    "\n",
    "# Imputation\n",
    "date_and_value_imputation=Date_And_Value_Imputation()\n",
    "\n",
    "# Features Daily Stats Module\n",
    "summary_stats_features=Summary_Stats_Features()\n",
    "\n",
    "# Features Complex\n",
    "ts_features=TS_Features()\n",
    "\n",
    "# Features Lagged Value\n",
    "create_lag_features=Create_Lagged_Features()\n",
    "\n",
    "# Features Differences\n",
    "difference_features=Difference_Features()\n",
    "\n",
    "# PySpark XGBoost Model Module\n",
    "create_pyspark_xgboost=Create_PySpark_XGBoost()\n",
    "\n",
    "# Classification Evaluation\n",
    "evaluate_model=Evaluate_Model()\n",
    "\n",
    "# Model Plots Feature Importance\n",
    "xgboost_classification_plot=XGBoost_Classification_Plot()\n",
    "\n",
    "# Feature Transformations\n",
    "feature_transformations=Feature_Transformations()\n",
    "\n",
    "\n",
    "pyspark_custom_imputation_schema=pandas_udf_data_schema.custom_imputation_pyspark_schema()\n",
    "\n",
    "\n",
    "model_predictions=Model_Predictions()\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance=Feature_Importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. PySpark: Reading In Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "|           PatientId|Value| GlucoseDisplayTime|GlucoseDisplayTimeRaw|GlucoseDisplayDate|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "|8W/rpnb48OMm47W2x...|328.0|2022-01-31 17:38:00| 2022-01-31T17:38:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|331.0|2022-01-31 17:43:00| 2022-01-31T17:43:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|329.0|2022-01-31 17:48:00| 2022-01-31T17:48:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|321.0|2022-01-31 17:53:00| 2022-01-31T17:53:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|315.0|2022-01-31 17:58:00| 2022-01-31T17:58:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|313.0|2022-01-31 18:03:00| 2022-01-31T18:03:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|304.0|2022-01-31 18:08:00| 2022-01-31T18:08:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|298.0|2022-01-31 18:13:00| 2022-01-31T18:13:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|294.0|2022-01-31 18:18:00| 2022-01-31T18:18:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|291.0|2022-01-31 18:23:00| 2022-01-31T18:23:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|289.0|2022-01-31 18:28:00| 2022-01-31T18:28:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|288.0|2022-01-31 18:33:00| 2022-01-31T18:33:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|286.0|2022-01-31 18:38:00| 2022-01-31T18:38:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|283.0|2022-01-31 18:43:00| 2022-01-31T18:43:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|282.0|2022-01-31 18:48:00| 2022-01-31T18:48:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|280.0|2022-01-31 18:53:00| 2022-01-31T18:53:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|278.0|2022-01-31 18:58:00| 2022-01-31T18:58:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|276.0|2022-01-31 19:03:00| 2022-01-31T19:03:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|274.0|2022-01-31 19:08:00| 2022-01-31T19:08:...|        2022-01-31|\n",
      "|8W/rpnb48OMm47W2x...|271.0|2022-01-31 19:13:00| 2022-01-31T19:13:...|        2022-01-31|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_df=reading_data.read_in_pyspark_training(training_data_location=train_data_storage)\n",
    "training_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "|           PatientId|Value| GlucoseDisplayTime|GlucoseDisplayTimeRaw|GlucoseDisplayDate|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 16:59:00| 2022-02-08T16:59:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 17:04:00| 2022-02-08T17:04:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 17:09:00| 2022-02-08T17:09:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 17:14:00| 2022-02-08T17:14:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 17:19:00| 2022-02-08T17:19:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|  0.0|2022-02-08 17:24:00| 2022-02-08T17:24:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|277.0|2022-02-08 17:29:00| 2022-02-08T17:29:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|270.0|2022-02-08 17:34:00| 2022-02-08T17:34:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|268.0|2022-02-08 17:39:00| 2022-02-08T17:39:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|259.0|2022-02-08 17:44:00| 2022-02-08T17:44:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|246.0|2022-02-08 17:49:00| 2022-02-08T17:49:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|232.0|2022-02-08 17:54:00| 2022-02-08T17:54:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|225.0|2022-02-08 17:59:00| 2022-02-08T17:59:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|228.0|2022-02-08 18:04:00| 2022-02-08T18:04:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|249.0|2022-02-08 18:09:00| 2022-02-08T18:09:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|273.0|2022-02-08 18:14:00| 2022-02-08T18:14:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|294.0|2022-02-08 18:19:00| 2022-02-08T18:19:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|308.0|2022-02-08 18:24:00| 2022-02-08T18:24:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|311.0|2022-02-08 18:29:00| 2022-02-08T18:29:...|        2022-02-08|\n",
      "|8W/rpnb48OMm47W2x...|307.0|2022-02-08 18:34:00| 2022-02-08T18:34:...|        2022-02-08|\n",
      "+--------------------+-----+-------------------+---------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_df=reading_data.read_in_pyspark_testing(testing_data_location=test_data_storage)\n",
    "testing_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. PySpark: Custom Imputation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/glucose-data-analysis/glucose_venv/lib/python3.10/site-packages/pyspark/sql/pandas/group_ops.py:98: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n",
      "[Stage 17:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+\n",
      "| GlucoseDisplayTime|           PatientId|Value|\n",
      "+-------------------+--------------------+-----+\n",
      "|2022-01-31 17:35:00|8W/rpnb48OMm47W2x...|328.0|\n",
      "+-------------------+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_custom_imputation_schema=pandas_udf_data_schema.custom_imputation_pyspark_schema()\n",
    "training_custom_imputation_pipeline=date_and_value_imputation.\\\n",
    "                                        pyspark_custom_imputation_pipeline(df=training_df, \n",
    "                                                                           output_schema=pyspark_custom_imputation_schema,\n",
    "                                                                           analysis_group=analysis_group)\n",
    "\n",
    "training_custom_imputation_pipeline.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 29:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+\n",
      "| GlucoseDisplayTime|           PatientId|    Value|\n",
      "+-------------------+--------------------+---------+\n",
      "|2022-02-08 16:55:00|8W/rpnb48OMm47W2x...|164.20488|\n",
      "+-------------------+--------------------+---------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "testing_custom_imputation_schema=pandas_udf_data_schema.custom_imputation_pyspark_schema()\n",
    "testing_custom_imputation_pipeline=date_and_value_imputation.\\\n",
    "                                        pyspark_custom_imputation_pipeline(df=testing_df, \n",
    "                                                                           output_schema=pyspark_custom_imputation_schema,\n",
    "                                                                           analysis_group=analysis_group)\n",
    "\n",
    "testing_custom_imputation_pipeline.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. PySpark: Adding Binary Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+--------+--------+--------+\n",
      "| GlucoseDisplayTime|           PatientId|Value|y_Binary|is_above|is_below|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+\n",
      "|2022-01-31 17:35:00|8W/rpnb48OMm47W2x...|328.0|       1|       1|       0|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df_added_binary_labels=create_binary_labels.pyspark_binary_labels(df=training_custom_imputation_pipeline)\n",
    "\n",
    "training_df_added_binary_labels.show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------------------------------+---------+--------+--------+--------+\n",
      "|GlucoseDisplayTime |PatientId                                   |Value    |y_Binary|is_above|is_below|\n",
      "+-------------------+--------------------------------------------+---------+--------+--------+--------+\n",
      "|2022-02-08 16:55:00|8W/rpnb48OMm47W2x4FSkc7+9u2mol061DQuJoMdiK0=|164.20488|0       |0       |0       |\n",
      "+-------------------+--------------------------------------------+---------+--------+--------+--------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_df_added_binary_labels=create_binary_labels.pyspark_binary_labels(df=testing_custom_imputation_pipeline)\n",
    "\n",
    "testing_df_added_binary_labels.show(1, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PySpark: Feature Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complex Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 89:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+\n",
      "| GlucoseDisplayTime|           PatientId|Value|y_Binary|is_above|is_below|FirstDiff|SecDiff|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+\n",
      "|2022-01-31 17:35:00|8W/rpnb48OMm47W2x...|328.0|       1|       1|       0|      0.0|    0.0|\n",
      "|2022-01-31 17:40:00|8W/rpnb48OMm47W2x...|331.0|       1|       1|       0|      3.0|    3.0|\n",
      "|2022-01-31 17:45:00|8W/rpnb48OMm47W2x...|329.0|       1|       1|       0|     -2.0|   -5.0|\n",
      "|2022-01-31 17:50:00|8W/rpnb48OMm47W2x...|321.0|       1|       1|       0|     -8.0|   -6.0|\n",
      "|2022-01-31 17:55:00|8W/rpnb48OMm47W2x...|315.0|       1|       1|       0|     -6.0|    2.0|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "training_df_differences = difference_features.add_difference_features(training_df_added_binary_labels)\n",
    "training_df_differences.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+-----+-----+\n",
      "| GlucoseDisplayTime|           PatientId|Value|y_Binary|is_above|is_below|FirstDiff|SecDiff|index|Chunk|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+-----+-----+\n",
      "|2022-01-31 17:35:00|8W/rpnb48OMm47W2x...|328.0|       1|       1|       0|      0.0|    0.0|    1|    0|\n",
      "|2022-01-31 17:40:00|8W/rpnb48OMm47W2x...|331.0|       1|       1|       0|      3.0|    3.0|    2|    0|\n",
      "|2022-01-31 17:45:00|8W/rpnb48OMm47W2x...|329.0|       1|       1|       0|     -2.0|   -5.0|    3|    0|\n",
      "|2022-01-31 17:50:00|8W/rpnb48OMm47W2x...|321.0|       1|       1|       0|     -8.0|   -6.0|    4|    0|\n",
      "|2022-01-31 17:55:00|8W/rpnb48OMm47W2x...|315.0|       1|       1|       0|     -6.0|    2.0|    5|    0|\n",
      "+-------------------+--------------------+-----+--------+--------+--------+---------+-------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df_chunks = summary_stats_features.create_chunk_col(training_df_differences, chunk_val = 288)\n",
    "training_df_chunks.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_df_poincare = training_df_chunks.groupby(['PatientId', 'Chunk']).apply(ts_features.poincare)\n",
    "# training_df_poincare.show(5)\n",
    "\n",
    "# training_df_entropy = training_df_chunks.groupby(['PatientId', 'Chunk']).apply(ts_features.entropy)\n",
    "# training_df_entropy.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_df_complex_features = training_df_poincare.join(training_df_entropy,['PatientId', 'Chunk'])\n",
    "# training_df_complex_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_df_sleep = ts_features.process_for_sleep(df=training_df_added_binary_labels)\n",
    "# training_df_sleep.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "|           PatientId|Chunk|              Mean|            StdDev|Median|  Min|  Max|        AvgFirstDiff|          AvgSecDiff|      StdFirstDiff|        StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|target|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "|8W/rpnb48OMm47W2x...|    1|250.30549891789755| 60.39017986635174| 240.0|161.0|401.0|-0.10877741707695855|0.003472222222222222|5.9481085344362254| 5.444201337481776|       134|         0|            134|  -105|\n",
      "|8W/rpnb48OMm47W2x...|    2|214.40972222222223|42.174007087187746| 207.0|160.0|301.0|  0.2673611111111111|-0.00694444444444...| 4.337830184821668|3.8071938650169472|        84|         0|             84|    50|\n",
      "|8W/rpnb48OMm47W2x...|    3|             240.0|  59.2138979825321| 234.0|133.0|381.0|-0.17708333333333334|0.006944444444444444| 5.601757050760872|  5.73940050503374|       133|         0|            133|   -49|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_features_summary_stats=summary_stats_features.pyspark_summary_statistics(df=training_df_chunks)\n",
    "# merge complex features and summary stats and demographics and sleep features\n",
    "# merge in one hot encoded cohort file info demographics\n",
    "    # '/cephfs/data/cohort_encoded.parquet' (gender, treatment, age category)\n",
    "    # groupby patientId and chunk\n",
    "\n",
    "training_features_summary_stats.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #add target variable\n",
    "# training_features_final_summary = summary_stats_features\\\n",
    "#                                     .add_lag_out_of_range(df=training_features_summary_stats, chunk_lag=1)\n",
    "\n",
    "# training_features_final_summary.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge these together\n",
    "# training_features_summary_stats\n",
    "# training_df_complex_features\n",
    "# one-hot-encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Complex Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+\n",
      "| GlucoseDisplayTime|           PatientId|    Value|y_Binary|is_above|is_below|FirstDiff|SecDiff|\n",
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+\n",
      "|2022-02-08 16:55:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|\n",
      "|2022-02-08 17:00:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|\n",
      "|2022-02-08 17:05:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|\n",
      "|2022-02-08 17:10:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|\n",
      "|2022-02-08 17:15:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|\n",
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_df_differences = difference_features.add_difference_features(testing_df_added_binary_labels)\n",
    "testing_df_differences.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+-----+-----+\n",
      "| GlucoseDisplayTime|           PatientId|    Value|y_Binary|is_above|is_below|FirstDiff|SecDiff|index|Chunk|\n",
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+-----+-----+\n",
      "|2022-02-08 16:55:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|    1|    0|\n",
      "|2022-02-08 17:00:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|    2|    0|\n",
      "|2022-02-08 17:05:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|    3|    0|\n",
      "|2022-02-08 17:10:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|    4|    0|\n",
      "|2022-02-08 17:15:00|8W/rpnb48OMm47W2x...|164.20488|       0|       0|       0|      0.0|    0.0|    5|    0|\n",
      "+-------------------+--------------------+---------+--------+--------+--------+---------+-------+-----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_df_chunks = summary_stats_features.create_chunk_col(testing_df_differences, chunk_val = 288)\n",
    "testing_df_chunks.show(5)\n",
    "\n",
    "# testing_df_poincare = testing_df_chunks.groupby(['PatientId', 'Chunk']).apply(ts_features.poincare)\n",
    "# testing_df_poincare.show(5)\n",
    "\n",
    "# testing_df_entropy = testing_df_chunks.groupby(['PatientId', 'Chunk']).apply(ts_features.entropy)\n",
    "# testing_df_entropy.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# testing_df_complex_features = testing_df_poincare.join(testing_df_entropy,['PatientId', 'Chunk'])\n",
    "# testing_df_complex_features.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training_df_sleep = ts_features.process_for_sleep(df=testing_df_added_binary_labels)\n",
    "# training_df_sleep.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+-------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "|           PatientId|Chunk|              Mean|            StdDev|Median|  Min|  Max|       AvgFirstDiff|         AvgSecDiff|      StdFirstDiff|        StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|target|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+-------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "|8W/rpnb48OMm47W2x...|    1| 139.6583505206638|36.561064568332455| 135.0| 66.0|247.0| 0.1701388888888889|             0.0625|  8.68154980903809|12.418971213537594|         3|         1|              4|    49|\n",
      "|8W/rpnb48OMm47W2x...|    2|253.55555555555554| 5.246692079565728| 255.0|245.0|260.0|-0.2222222222222222|-0.8888888888888888|  3.73422608373468|2.6193722742502854|         9|         0|              9|    -5|\n",
      "|CzndP9OQqEYW/LY7h...|    1|150.66319444444446|46.753275234582944| 152.0| 70.0|251.0| 0.1388888888888889|           -0.03125|5.9076647916708325| 5.917174774930444|        13|         0|             13|    77|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+-------------------+------------------+------------------+----------+----------+---------------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_features_summary_stats=summary_stats_features.pyspark_summary_statistics(df=testing_df_chunks)\n",
    "\n",
    "# merge complex features and summary stats and demographics and sleep features\n",
    "# merge in one hot encoded cohort file info demographics\n",
    "    # '/cephfs/data/cohort_encoded.parquet' (gender, treatment, age category)\n",
    "    # groupby patientId and chunk\n",
    "\n",
    "testing_features_summary_stats.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge these together\n",
    "# testing_features_summary_stats\n",
    "# training_df_complex_features\n",
    "# one-hot-encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. PySpark: Sklearn Categorical Pipeline in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_hot_encoded_df=reading_data.read_in_one_hot_encoded_data(one_hot_encoding_location=one_hot_encoding_data)\n",
    "one_hot_encoded_df=one_hot_encoded_df.select('UserId', \n",
    "                                             'Sex_Encoded', \n",
    "                                             'Treatment_Encoded', \n",
    "                                             'AgeGroup_Encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_encoded=training_features_summary_stats.join(one_hot_encoded_df,\n",
    "                                                       training_features_summary_stats.PatientId==one_hot_encoded_df.UserId,\n",
    "                                                       \"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-----------+-----------------+----------------+\n",
      "|           PatientId|Chunk|              Mean|            StdDev|Median|  Min|  Max|        AvgFirstDiff|          AvgSecDiff|      StdFirstDiff|        StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|target|              UserId|Sex_Encoded|Treatment_Encoded|AgeGroup_Encoded|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-----------+-----------------+----------------+\n",
      "|8W/rpnb48OMm47W2x...|    1|250.30549891789755| 60.39017986635174| 240.0|161.0|401.0|-0.10877741707695855|0.003472222222222222|5.9481085344362254| 5.444201337481776|       134|         0|            134|  -105|8W/rpnb48OMm47W2x...|  (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "|8W/rpnb48OMm47W2x...|    2|214.40972222222223|42.174007087187746| 207.0|160.0|301.0|  0.2673611111111111|-0.00694444444444...| 4.337830184821668|3.8071938650169472|        84|         0|             84|    50|8W/rpnb48OMm47W2x...|  (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "|8W/rpnb48OMm47W2x...|    3|             240.0|  59.2138979825321| 234.0|133.0|381.0|-0.17708333333333334|0.006944444444444444| 5.601757050760872|  5.73940050503374|       133|         0|            133|   -49|8W/rpnb48OMm47W2x...|  (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "|8W/rpnb48OMm47W2x...|    4|245.35069444444446| 78.71333735059129| 228.0|148.0|401.0|  0.1527777777777778|-0.02430555555555...| 5.382666003233119| 5.952433362138609|       111|         0|            111|    22|8W/rpnb48OMm47W2x...|  (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+--------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-----------+-----------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_encoded.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# merge training_features_summary with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testing_encoded=testing_features_summary_stats.join(one_hot_encoded_df,\n",
    "                                                       testing_features_summary_stats.PatientId==one_hot_encoded_df.UserId,\n",
    "                                                       \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-------------+-----------------+----------------+\n",
      "|           PatientId|Chunk|              Mean|            StdDev|Median|  Min|  Max|       AvgFirstDiff|          AvgSecDiff|      StdFirstDiff|        StdSecDiff|CountAbove|CountBelow|TotalOutOfRange|target|              UserId|  Sex_Encoded|Treatment_Encoded|AgeGroup_Encoded|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-------------+-----------------+----------------+\n",
      "|8W/rpnb48OMm47W2x...|    1| 139.6583505206638|36.561064568332455| 135.0| 66.0|247.0| 0.1701388888888889|              0.0625|  8.68154980903809|12.418971213537594|         3|         1|              4|    49|8W/rpnb48OMm47W2x...|    (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "|8W/rpnb48OMm47W2x...|    2|253.55555555555554| 5.246692079565728| 255.0|245.0|260.0|-0.2222222222222222| -0.8888888888888888|  3.73422608373468|2.6193722742502854|         9|         0|              9|    -5|8W/rpnb48OMm47W2x...|    (1,[],[])|    (3,[1],[1.0])|   (7,[0],[1.0])|\n",
      "|CzndP9OQqEYW/LY7h...|    1|150.66319444444446|46.753275234582944| 152.0| 70.0|251.0| 0.1388888888888889|            -0.03125|5.9076647916708325| 5.917174774930444|        13|         0|             13|    77|CzndP9OQqEYW/LY7h...|(1,[0],[1.0])|    (3,[0],[1.0])|   (7,[0],[1.0])|\n",
      "|CzndP9OQqEYW/LY7h...|    2|201.44444444444446|17.198688083539178| 202.0|169.0|229.0| 1.9259259259259258|0.037037037037037035| 6.207476422247895|  7.71851660460082|         0|         0|              0|    13|CzndP9OQqEYW/LY7h...|(1,[0],[1.0])|    (3,[0],[1.0])|   (7,[0],[1.0])|\n",
      "+--------------------+-----+------------------+------------------+------+-----+-----+-------------------+--------------------+------------------+------------------+----------+----------+---------------+------+--------------------+-------------+-----------------+----------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_encoded.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. PySpark: Sklearn Numerical Pipeline in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_numerical_stages=feature_transformations.numerical_scaling(df=training_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. PySpark: XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You enabled use_gpu in spark local mode. Please make sure your local node has at least 4 GPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/05/04 19:42:46 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:42:52] task 0 got new rank 0                                    (0 + 4) / 4]\n",
      "[19:42:52] task 3 got new rank 1\n",
      "[19:42:52] task 1 got new rank 2\n",
      "[19:42:52] task 2 got new rank 3\n",
      "/home/jovyan/glucose-data-analysis/glucose_venv/lib/python3.10/site-packages/xgboost/sklearn.py:782: UserWarning: Loading a native XGBoost model with Scikit-Learn interface.\n",
      "  warnings.warn(\"Loading a native XGBoost model with Scikit-Learn interface.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:42:55] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You enabled use_gpu in spark local mode. Please make sure your local node has at least 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "xgboost_model=create_pyspark_xgboost.xgboost_classifier(ml_df=training_encoded,\n",
    "                                                        stages=training_numerical_stages,\n",
    "                                                        model_storage_location=model_storage_location,\n",
    "                                                        random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. PySpark: Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. PySpark: Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+------------------+\n",
      "|           PatientId|Chunk|target|        prediction|\n",
      "+--------------------+-----+------+------------------+\n",
      "|8W/rpnb48OMm47W2x...|    1|    49| 50.97040557861328|\n",
      "|8W/rpnb48OMm47W2x...|    2|    -5|-5.244208812713623|\n",
      "|CzndP9OQqEYW/LY7h...|    1|    77|  67.7061767578125|\n",
      "|CzndP9OQqEYW/LY7h...|    2|    13| 10.86211109161377|\n",
      "|ER+gxKFxHvXyfESG6...|    1|   -33|-39.08769226074219|\n",
      "|ER+gxKFxHvXyfESG6...|    2|    55| 50.81527328491211|\n",
      "|UNrE+DKLY8WEQsGhg...|    1|     8|0.8498030304908752|\n",
      "|UNrE+DKLY8WEQsGhg...|    2|    27|25.882190704345703|\n",
      "|WFanQktw0own7cwMg...|    1|   -22| -21.9498291015625|\n",
      "|WFanQktw0own7cwMg...|    2|    21|19.890609741210938|\n",
      "+--------------------+-----+------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:43:04] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testing_predictions=model_predictions.create_predictions_with_model(test_df=testing_encoded, \n",
    "                                                                    model=xgboost_model)\n",
    "testing_predictions.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. PySpark: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:43:28] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[19:43:29] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[19:43:30] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[19:43:32] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n",
      "[19:43:33] WARNING: ../src/learner.cc:553: \n",
      "  If you are loading a serialized model (like pickle in Python, RDS in R) generated by\n",
      "  older XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for more details about differences between saving model and serializing.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_evaluation=evaluate_model.regression_evaluation(testing_predictions=testing_predictions, \n",
    "                                                          eval_csv_location=evaluation_metrics_output_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.488376</td>\n",
       "      <td>20.145517</td>\n",
       "      <td>0.97762</td>\n",
       "      <td>3.078903</td>\n",
       "      <td>937.275385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rmse        mse       r2       mae         var\n",
       "0  4.488376  20.145517  0.97762  3.078903  937.275385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. PySpark: XGBoost Classification Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importance_df=feature_importance.\\\n",
    "                        feature_importance_accuracy_gain(xgboost_model=xgboost_model, \n",
    "                                                         feature_importance_storage_location=feature_importance_storage_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Accuracy Gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scaled_target</td>\n",
       "      <td>630.705566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>scaled_Max</td>\n",
       "      <td>14.202221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scaled_TotalOutOfRange</td>\n",
       "      <td>3.835952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>scaled_CountBelow</td>\n",
       "      <td>2.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scaled_StdFirstDiff</td>\n",
       "      <td>1.518541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>scaled_Min</td>\n",
       "      <td>1.033857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>scaled_AvgSecDiff</td>\n",
       "      <td>0.939486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>scaled_StdDev</td>\n",
       "      <td>0.254810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>scaled_CountAbove</td>\n",
       "      <td>0.096602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scaled_Mean</td>\n",
       "      <td>0.050581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature  Accuracy Gain\n",
       "0           scaled_target     630.705566\n",
       "1              scaled_Max      14.202221\n",
       "2  scaled_TotalOutOfRange       3.835952\n",
       "3       scaled_CountBelow       2.090200\n",
       "4     scaled_StdFirstDiff       1.518541\n",
       "5              scaled_Min       1.033857\n",
       "6       scaled_AvgSecDiff       0.939486\n",
       "7           scaled_StdDev       0.254810\n",
       "8       scaled_CountAbove       0.096602\n",
       "9             scaled_Mean       0.050581"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. PySpark: Feature Importance Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overall_feature_plot=xgboost_classification_plot.feature_overall_importance_plot(feature_importance_df=feature_importance_df,\n",
    "                                                                                 overall_importance_plot_location=overall_feature_importance_plot_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_feature_plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.PySpark: Local Level Feature Importance --> Shap Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add to reqs if this works\n",
    "! pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgboost_model.stages[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(xgboost_model.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glucose-venv",
   "language": "python",
   "name": "glucose-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e282f9bbb605e17ec33c138684786f2c6a0e45a19b318784bb5671e7a7934052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
